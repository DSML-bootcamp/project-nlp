{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329b2a1b-1054-486e-bade-635cd52fb471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\emin.sen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emin.sen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\emin.sen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================----------------------------------] 32.5% 311.6/958.4MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 98.6% 945.2/958.4MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "C:\\Users\\emin.sen\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 1s/step - accuracy: 0.4978 - loss: 0.6956 - val_accuracy: 0.5109 - val_loss: 0.6804\n",
      "Epoch 2/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 1s/step - accuracy: 0.5370 - loss: 0.6916 - val_accuracy: 0.5205 - val_loss: 0.6805\n",
      "Epoch 3/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 2s/step - accuracy: 0.5333 - loss: 0.6810 - val_accuracy: 0.5142 - val_loss: 0.6783\n",
      "Epoch 4/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 2s/step - accuracy: 0.5311 - loss: 0.6823 - val_accuracy: 0.5197 - val_loss: 0.6771\n",
      "Epoch 5/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 1s/step - accuracy: 0.5365 - loss: 0.6823 - val_accuracy: 0.5193 - val_loss: 0.6804\n",
      "Epoch 6/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 2s/step - accuracy: 0.5476 - loss: 0.6749 - val_accuracy: 0.5352 - val_loss: 0.6785\n",
      "Epoch 7/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 2s/step - accuracy: 0.5615 - loss: 0.6740 - val_accuracy: 0.5222 - val_loss: 0.6782\n",
      "Epoch 8/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 2s/step - accuracy: 0.5548 - loss: 0.6759 - val_accuracy: 0.5126 - val_loss: 0.6842\n",
      "Epoch 9/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 2s/step - accuracy: 0.5612 - loss: 0.6734 - val_accuracy: 0.5272 - val_loss: 0.6883\n",
      "Epoch 10/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 2s/step - accuracy: 0.5767 - loss: 0.6705 - val_accuracy: 0.5176 - val_loss: 0.6862\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 680ms/step\n",
      "Accuracy: 0.5219430485762144\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55      1519\n",
      "           1       0.51      0.46      0.49      1466\n",
      "\n",
      "    accuracy                           0.52      2985\n",
      "   macro avg       0.52      0.52      0.52      2985\n",
      "weighted avg       0.52      0.52      0.52      2985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import gensim.downloader as api\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('TRAINING_DATA.txt', delimiter='\\t')\n",
    "\n",
    "# Rename columns for easier reference\n",
    "df.columns = ['label', 'sentence']\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "\n",
    "df['sentence'] = df['sentence'].apply(preprocess_text)\n",
    "\n",
    "# Load pre-trained FastText embeddings\n",
    "fasttext_model = api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['sentence'])\n",
    "sequences = tokenizer.texts_to_sequences(df['sentence'])\n",
    "\n",
    "# Pad sequences to ensure equal length\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Convert labels to numpy array\n",
    "y = df['label'].values\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_dim = 300\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in fasttext_model:\n",
    "        embedding_matrix[i] = fasttext_model[word]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word_index) + 1,\n",
    "              output_dim=embedding_dim,\n",
    "              weights=[embedding_matrix],\n",
    "              input_length=max_sequence_length,\n",
    "              trainable=False),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "207b8313-111b-4761-9aa7-ae35f7d92f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 515ms/step\n",
      "                                               sentence  predicted_label\n",
      "0     \\tyo no creo que a nadie le haya encantado un ...                0\n",
      "1     \\tno va a resolver sus problemas de crédito o ...                0\n",
      "2                                \\tte encantará este \\n                1\n",
      "3     \\tyo estaba a volar a un aeropuerto varias hor...                1\n",
      "4     \\t maid en manhattan  the wedding planner  jer...                1\n",
      "...                                                 ...              ...\n",
      "2196  \\trobert pattinson se está moviendo desde su i...                0\n",
      "2197                                \\tera tan fresco \\n                0\n",
      "2198  \\tal salir de la sala de ensayos de laboratori...                0\n",
      "2199  \\t bueno  si usted pensaba que no era bueno pa...                1\n",
      "2200  \\tcuando josh tenía  años  se sentó con las pi...                0\n",
      "\n",
      "[2201 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the real data for prediction\n",
    "real_data_file = 'REAL_DATA.txt'\n",
    "with open(real_data_file, 'r', encoding='utf-8') as file:\n",
    "    sentences = file.readlines()\n",
    "\n",
    "# Create a DataFrame\n",
    "real_data = pd.DataFrame(sentences, columns=['sentence'])\n",
    "\n",
    "# Preprocess the real data\n",
    "real_data['sentence'] = real_data['sentence'].apply(preprocess_text)\n",
    "\n",
    "# Tokenize the real data sentences\n",
    "real_sequences = tokenizer.texts_to_sequences(real_data['sentence'])\n",
    "\n",
    "# Pad sequences to ensure equal length\n",
    "X_real = pad_sequences(real_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Make predictions on the real data\n",
    "real_data_pred_prob = model.predict(X_real)\n",
    "real_data_predictions = (real_data_pred_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "# Add predictions to the real_data dataframe\n",
    "real_data['label'] = real_data_predictions\n",
    "\n",
    "\n",
    "\n",
    "# Print the predictions\n",
    "print(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e23770d-7c43-4c2a-9997-dc44dd19e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 1s/step\n",
      "                                               sentence  label\n",
      "0     \\tyo no creo que a nadie le haya encantado un ...      0\n",
      "1     \\tno va a resolver sus problemas de crédito o ...      0\n",
      "2                                \\tte encantará este \\n      1\n",
      "3     \\tyo estaba a volar a un aeropuerto varias hor...      1\n",
      "4     \\t maid en manhattan  the wedding planner  jer...      1\n",
      "...                                                 ...    ...\n",
      "2196  \\trobert pattinson se está moviendo desde su i...      0\n",
      "2197                                \\tera tan fresco \\n      0\n",
      "2198  \\tal salir de la sala de ensayos de laboratori...      0\n",
      "2199  \\t bueno  si usted pensaba que no era bueno pa...      1\n",
      "2200  \\tcuando josh tenía  años  se sentó con las pi...      0\n",
      "\n",
      "[2201 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the real data for prediction\n",
    "real_data_file = 'REAL_DATA.txt'\n",
    "with open(real_data_file, 'r', encoding='utf-8') as file:\n",
    "    sentences = file.readlines()\n",
    "\n",
    "# Create a DataFrame\n",
    "real_data = pd.DataFrame(sentences, columns=['sentence'])\n",
    "\n",
    "# Preprocess the real data\n",
    "real_data['sentence'] = real_data['sentence'].apply(preprocess_text)\n",
    "\n",
    "# Tokenize the real data sentences\n",
    "real_sequences = tokenizer.texts_to_sequences(real_data['sentence'])\n",
    "\n",
    "# Pad sequences to ensure equal length\n",
    "X_real = pad_sequences(real_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Make predictions on the real data\n",
    "real_data_pred_prob = model.predict(X_real)\n",
    "real_data_predictions = (real_data_pred_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "# Add predictions to the real_data dataframe\n",
    "real_data['label'] = real_data_predictions\n",
    "\n",
    "\n",
    "\n",
    "# Print the predictions\n",
    "print(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e461b4ea-76c7-46ff-8fb1-d839ae3f5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270de8b8-f362-4631-9512-7344f8be9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final results as a CSV file\n",
    "real_data.to_csv('Real_Data_Predicted2.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b76e0f93-309d-48a6-8582-391bdd65137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns: Index(['sentence', 'label'], dtype='object')\n",
      "Modified columns: Index(['label', 'sentence'], dtype='object')\n",
      "   label                                           sentence\n",
      "0      0  \\tyo no creo que a nadie le haya encantado un ...\n",
      "1      0  \\tno va a resolver sus problemas de crédito o ...\n",
      "2      1                             \\tte encantará este \\n\n",
      "3      1  \\tyo estaba a volar a un aeropuerto varias hor...\n",
      "4      1  \\t maid en manhattan  the wedding planner  jer...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Print the original columns\n",
    "print(\"Original columns:\", real_data.columns)\n",
    "\n",
    "# Move the second column to the first position\n",
    "cols = real_data.columns.tolist()\n",
    "cols.insert(0, cols.pop(1))  # Pop the second column and insert it at the first position\n",
    "real_data = real_data[cols]\n",
    "\n",
    "# Print the new columns to verify\n",
    "print(\"Modified columns:\", real_data.columns)\n",
    "\n",
    "# Save the modified DataFrame to a .txt file with tab-separated values and without column names\n",
    "real_data.to_csv('real_data_predicted2.txt', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Verify the changes\n",
    "print(real_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23efd482-7a34-4bd9-b9ac-bca199c41636",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m report\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpectations\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "report.to_csv('expectations', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e063f7da-13d0-4163-a80e-0eb7eaaf2c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5219430485762144\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55      1519\n",
      "           1       0.51      0.46      0.49      1466\n",
      "\n",
      "    accuracy                           0.52      2985\n",
      "   macro avg       0.52      0.52      0.52      2985\n",
      "weighted avg       0.52      0.52      0.52      2985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_str = f\"Accuracy: {accuracy}\\n\\nClassification Report:\\n{report}\"\n",
    "\n",
    "# Save the report to a .txt file\n",
    "with open('expectations.txt', 'w') as file:\n",
    "    file.write(report_str)\n",
    "\n",
    "# Print the report to verify\n",
    "print(report_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
